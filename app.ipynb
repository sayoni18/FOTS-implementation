{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "app.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4buclG2cRQn",
        "outputId": "50c685f1-0a8f-421d-bd98-af9803de6ffe"
      },
      "source": [
        "!pip install -q pyngrok"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▍                               | 10kB 12.0MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 15.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 19.7MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 11.9MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 8.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 9.2MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 8.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81kB 8.4MB/s eta 0:00:01\r\u001b[K     |████                            | 92kB 8.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102kB 8.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 112kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 122kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 133kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 143kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 153kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 163kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 174kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 184kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 194kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 204kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 215kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 225kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 235kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 245kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 256kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 266kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 276kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 286kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 296kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 307kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 317kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 337kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 348kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 358kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 368kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 378kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 389kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 399kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 409kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 419kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 430kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 440kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 450kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 460kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 471kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 481kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 491kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 501kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 512kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 522kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 532kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 542kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 552kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 563kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 573kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 583kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 593kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 604kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 614kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 624kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 634kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 645kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 655kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 665kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 675kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 686kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 696kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 706kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 716kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 727kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 737kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 747kB 8.8MB/s \n",
            "\u001b[?25h  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "vOUM53XfcaIR",
        "outputId": "c500abdf-4343-43dc-8eb3-ea5a21bfaf58"
      },
      "source": [
        "!pip install -U ipykernel"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipykernel\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/2d/cff3898f2f58f41b1031c9f98501992ae0c8378919213b88884a1db064c2/ipykernel-5.5.4-py3-none-any.whl (120kB)\n",
            "\r\u001b[K     |██▊                             | 10kB 13.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 20kB 19.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 30kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 40kB 10.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 51kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 61kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 71kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 81kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 92kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 102kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 112kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.0.5)\n",
            "Requirement already satisfied, skipping upgrade: ipython>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.5.0)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.3.5)\n",
            "Requirement already satisfied, skipping upgrade: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.1.1)\n",
            "Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.1.0->ipykernel) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (0.7.5)\n",
            "Requirement already satisfied, skipping upgrade: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (1.0.18)\n",
            "Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (4.8.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (56.1.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel) (4.7.1)\n",
            "Requirement already satisfied, skipping upgrade: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel) (22.0.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0->ipykernel) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0->ipykernel) (0.2.5)\n",
            "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel) (0.7.0)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.5.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: ipykernel\n",
            "  Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "Successfully installed ipykernel-5.5.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipykernel"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WijA6ATMcoFY",
        "outputId": "e1fd8972-b997-4323-ef7b-e6f50f1f9467"
      },
      "source": [
        "!pip install pyngrok"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.7/dist-packages (5.0.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GAUy90JczBl",
        "outputId": "18af4110-973b-4c9c-9f31-02d2d6fa9dba"
      },
      "source": [
        "!pip install -q streamlit_ace"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.9MB 9.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.2MB 35.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2MB 38.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 47.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 47.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 5.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 6.9MB/s \n",
            "\u001b[?25h  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDW1chPqiZnw",
        "outputId": "bf05b065-2fd8-4e9d-99e6-8371bab6b378"
      },
      "source": [
        "pip install Pillow"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B90ohCreuln",
        "outputId": "2aade930-cb5c-44e7-9a1f-6020a50d12f3"
      },
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "from time import time\n",
        "import cv2\n",
        "from zipfile import ZipFile\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import threading\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "import csv\n",
        "from itertools import compress\n",
        "import cv2\n",
        "import time\n",
        "import shutil\n",
        "import scipy.io as sio\n",
        "import os\n",
        "import numpy as np\n",
        "import scipy.optimize\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as Patches\n",
        "from shapely.geometry import Polygon\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import multiprocessing\n",
        "try:\n",
        "    import queue\n",
        "except ImportError:\n",
        "    import Queue as queue\n",
        "\n",
        "import glob\n",
        "\n",
        "\n",
        "\n",
        "CHAR_VECTOR = \" 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZÉ´-~`<>'.:;^/|!?$%#@&*()[]{}_+=,\\\\\\\"\"\n",
        "NUM_CLASSES = len(CHAR_VECTOR) \n",
        "char_index={}\n",
        "index_char={}\n",
        "for i,val in enumerate(CHAR_VECTOR):\n",
        "  index_char[i+1]=val\n",
        "  char_index[val]=i+1\n",
        "def polygon_area(poly):\n",
        "    '''\n",
        "    compute area of a polygon\n",
        "    '''\n",
        "    edge = [\n",
        "        (poly[1][0] - poly[0][0]) * (poly[1][1] + poly[0][1]),\n",
        "        (poly[2][0] - poly[1][0]) * (poly[2][1] + poly[1][1]),\n",
        "        (poly[3][0] - poly[2][0]) * (poly[3][1] + poly[2][1]),\n",
        "        (poly[0][0] - poly[3][0]) * (poly[0][1] + poly[3][1])\n",
        "    ]\n",
        "    return np.sum(edge)/2.\n",
        "\n",
        "def check_and_validate_polys(polys, tags, xxx_todo_changeme):\n",
        "\n",
        "\n",
        "    def is_polygon(poly):\n",
        "        for i in range(3):\n",
        "            p0 = poly[i]\n",
        "\n",
        "        p1 = poly[(i + 1) % 4]\n",
        "        p2 = poly[(i + 2) % 4]\n",
        "    \n",
        "        if p0[0] == p1[0] and p1[1] == p0[1]:\n",
        "            return False\n",
        "        if p0[0] == p2[0] and p2[1] == p0[1]:\n",
        "            return False\n",
        "        if p1[0] == p2[0] and p1[1] == p2[1]:\n",
        "            return False\n",
        "    \n",
        "        if p0[0] == p1[0]:\n",
        "            if p1[0] == p2[0]:\n",
        "                return False\n",
        "        else:\n",
        "            if p1[0] != p2[0]:\n",
        "                k1 = (p1[1] - p0[1]) / (p1[0] - p0[0])\n",
        "                k2 = (p2[1] - p1[1]) / (p2[0] - p1[0])\n",
        "                if abs(k1 - k2) < 1e-6:\n",
        "                    return False\n",
        "                else:\n",
        "                    if p1[1] == p2[1]:\n",
        "                        return False\n",
        "        \n",
        "        return True\n",
        "\n",
        "    (h, w) = xxx_todo_changeme\n",
        "    if polys.shape[0] == 0:\n",
        "        return polys\n",
        "    polys[:, :, 0] = np.clip(polys[:, :, 0], 0, w - 1)\n",
        "    polys[:, :, 1] = np.clip(polys[:, :, 1], 0, h - 1)\n",
        "\n",
        "    validated_polys = []\n",
        "    validated_tags = []\n",
        "    for poly, tag in zip(polys, tags):\n",
        "        p_area = polygon_area(poly)\n",
        "\n",
        "        if is_polygon(poly) is False:\n",
        "            continue\n",
        "\n",
        "        if abs(p_area) < 1:\n",
        "            continue\n",
        "        if p_area > 0:\n",
        "            poly = poly[(0, 3, 2, 1), :]\n",
        "        validated_polys.append(poly)\n",
        "        validated_tags.append(tag)\n",
        "    return np.array(validated_polys), np.array(validated_tags)    \n",
        "    \n",
        "def shrink_poly(poly, r):\n",
        "    '''\n",
        "    fit a poly inside the origin poly\n",
        "    used for generate the score map\n",
        "    '''\n",
        "    # shrink ratio\n",
        "    R = 0.3\n",
        "    # find the longer pair\n",
        "    if np.linalg.norm(poly[0] - poly[1]) + np.linalg.norm(poly[2] - poly[3]) > \\\n",
        "                    np.linalg.norm(poly[0] - poly[3]) + np.linalg.norm(poly[1] - poly[2]):\n",
        "        # first move (p0, p1), (p2, p3), then (p0, p3), (p1, p2)\n",
        "        ## p0, p1\n",
        "        theta = np.arctan2((poly[1][1] - poly[0][1]), (poly[1][0] - poly[0][0]))\n",
        "        poly[0][0] += R * r[0] * np.cos(theta)\n",
        "        poly[0][1] += R * r[0] * np.sin(theta)\n",
        "        poly[1][0] -= R * r[1] * np.cos(theta)\n",
        "        poly[1][1] -= R * r[1] * np.sin(theta)\n",
        "        ## p2, p3\n",
        "        theta = np.arctan2((poly[2][1] - poly[3][1]), (poly[2][0] - poly[3][0]))\n",
        "        poly[3][0] += R * r[3] * np.cos(theta)\n",
        "        poly[3][1] += R * r[3] * np.sin(theta)\n",
        "        poly[2][0] -= R * r[2] * np.cos(theta)\n",
        "        poly[2][1] -= R * r[2] * np.sin(theta)\n",
        "        ## p0, p3\n",
        "        theta = np.arctan2((poly[3][0] - poly[0][0]), (poly[3][1] - poly[0][1]))\n",
        "        poly[0][0] += R * r[0] * np.sin(theta)\n",
        "        poly[0][1] += R * r[0] * np.cos(theta)\n",
        "        poly[3][0] -= R * r[3] * np.sin(theta)\n",
        "        poly[3][1] -= R * r[3] * np.cos(theta)\n",
        "        ## p1, p2\n",
        "        theta = np.arctan2((poly[2][0] - poly[1][0]), (poly[2][1] - poly[1][1]))\n",
        "        poly[1][0] += R * r[1] * np.sin(theta)\n",
        "        poly[1][1] += R * r[1] * np.cos(theta)\n",
        "        poly[2][0] -= R * r[2] * np.sin(theta)\n",
        "        poly[2][1] -= R * r[2] * np.cos(theta)\n",
        "    else:\n",
        "        ## p0, p3\n",
        "        # print poly\n",
        "        theta = np.arctan2((poly[3][0] - poly[0][0]), (poly[3][1] - poly[0][1]))\n",
        "        poly[0][0] += R * r[0] * np.sin(theta)\n",
        "        poly[0][1] += R * r[0] * np.cos(theta)\n",
        "        poly[3][0] -= R * r[3] * np.sin(theta)\n",
        "        poly[3][1] -= R * r[3] * np.cos(theta)\n",
        "        ## p1, p2\n",
        "        theta = np.arctan2((poly[2][0] - poly[1][0]), (poly[2][1] - poly[1][1]))\n",
        "        poly[1][0] += R * r[1] * np.sin(theta)\n",
        "        poly[1][1] += R * r[1] * np.cos(theta)\n",
        "        poly[2][0] -= R * r[2] * np.sin(theta)\n",
        "        poly[2][1] -= R * r[2] * np.cos(theta)\n",
        "        ## p0, p1\n",
        "        theta = np.arctan2((poly[1][1] - poly[0][1]), (poly[1][0] - poly[0][0]))\n",
        "        poly[0][0] += R * r[0] * np.cos(theta)\n",
        "        poly[0][1] += R * r[0] * np.sin(theta)\n",
        "        poly[1][0] -= R * r[1] * np.cos(theta)\n",
        "        poly[1][1] -= R * r[1] * np.sin(theta)\n",
        "        ## p2, p3\n",
        "        theta = np.arctan2((poly[2][1] - poly[3][1]), (poly[2][0] - poly[3][0]))\n",
        "        poly[3][0] += R * r[3] * np.cos(theta)\n",
        "        poly[3][1] += R * r[3] * np.sin(theta)\n",
        "        poly[2][0] -= R * r[2] * np.cos(theta)\n",
        "        poly[2][1] -= R * r[2] * np.sin(theta)\n",
        "    return poly\n",
        "\n",
        "def point_dist_to_line(p1, p2, p3):\n",
        "    '''compute the distance from p3 to p1-p2'''\n",
        "    return np.linalg.norm(np.cross(p2 - p1, p1 - p3)) / np.linalg.norm(p2 - p1)\n",
        "\n",
        "#Find equation of line using two 2D points p1 and p2\n",
        "def fit_line(p1, p2):\n",
        "    '''fit a line ax+by+c = 0'''\n",
        "    if p1[0] == p1[1]:\n",
        "        return [1., 0., -p1[0]]\n",
        "    else:\n",
        "        [k, b] = np.polyfit(p1, p2, deg=1)\n",
        "        return [k, -1., b]\n",
        "\n",
        "#Find Intersection poitn of 2 lines\n",
        "def line_cross_point(line1, line2):\n",
        "    '''line1 0= ax+by+c, compute the cross point of line1 and line2'''\n",
        "    if line1[0] != 0 and line1[0] == line2[0]:\n",
        "        print('Cross point does not exist')\n",
        "        return None\n",
        "    if line1[0] == 0 and line2[0] == 0:\n",
        "        print('Cross point does not exist')\n",
        "        return None\n",
        "    if line1[1] == 0:\n",
        "        x = -line1[2]\n",
        "        y = line2[0] * x + line2[2]\n",
        "    elif line2[1] == 0:\n",
        "        x = -line2[2]\n",
        "        y = line1[0] * x + line1[2]\n",
        "    else:\n",
        "        k1, _, b1 = line1\n",
        "        k2, _, b2 = line2\n",
        "        x = -(b1-b2)/(k1-k2)\n",
        "        y = k1*x + b1\n",
        "    return np.array([x, y], dtype=np.float32)\n",
        "\n",
        "#Get Equation of line that is perpendicular to line passing through a point\n",
        "def line_verticle(line, point):\n",
        "    '''get the verticle line from line across point'''\n",
        "    if line[1] == 0:\n",
        "        verticle = [0, -1, point[1]]\n",
        "    else:\n",
        "        if line[0] == 0:\n",
        "            verticle = [1, 0, -point[0]]\n",
        "        else:\n",
        "            verticle = [-1./line[0], -1, point[1] - (-1/line[0] * point[0])]\n",
        "    return verticle\n",
        "def rectangle_from_parallelogram(poly):\n",
        "    '''\n",
        "    fit a rectangle from a parallelogram\n",
        "    '''\n",
        "    p0, p1, p2, p3 = poly\n",
        "    angle_p0 = np.arccos(np.dot(p1-p0, p3-p0)/(np.linalg.norm(p0-p1) * np.linalg.norm(p3-p0)))\n",
        "    if angle_p0 < 0.5 * np.pi:\n",
        "        if np.linalg.norm(p0 - p1) > np.linalg.norm(p0-p3):\n",
        "            # p0 and p2\n",
        "            ## p0\n",
        "            p2p3 = fit_line([p2[0], p3[0]], [p2[1], p3[1]])\n",
        "            p2p3_verticle = line_verticle(p2p3, p0)\n",
        "\n",
        "            new_p3 = line_cross_point(p2p3, p2p3_verticle)\n",
        "            ## p2\n",
        "            p0p1 = fit_line([p0[0], p1[0]], [p0[1], p1[1]])\n",
        "            p0p1_verticle = line_verticle(p0p1, p2)\n",
        "\n",
        "            new_p1 = line_cross_point(p0p1, p0p1_verticle)\n",
        "            return np.array([p0, new_p1, p2, new_p3], dtype=np.float32)\n",
        "        else:\n",
        "            p1p2 = fit_line([p1[0], p2[0]], [p1[1], p2[1]])\n",
        "            p1p2_verticle = line_verticle(p1p2, p0)\n",
        "\n",
        "            new_p1 = line_cross_point(p1p2, p1p2_verticle)\n",
        "            p0p3 = fit_line([p0[0], p3[0]], [p0[1], p3[1]])\n",
        "            p0p3_verticle = line_verticle(p0p3, p2)\n",
        "\n",
        "            new_p3 = line_cross_point(p0p3, p0p3_verticle)\n",
        "            return np.array([p0, new_p1, p2, new_p3], dtype=np.float32)\n",
        "    else:\n",
        "        if np.linalg.norm(p0-p1) > np.linalg.norm(p0-p3):\n",
        "            # p1 and p3\n",
        "            ## p1\n",
        "            p2p3 = fit_line([p2[0], p3[0]], [p2[1], p3[1]])\n",
        "            p2p3_verticle = line_verticle(p2p3, p1)\n",
        "\n",
        "            new_p2 = line_cross_point(p2p3, p2p3_verticle)\n",
        "            ## p3\n",
        "            p0p1 = fit_line([p0[0], p1[0]], [p0[1], p1[1]])\n",
        "            p0p1_verticle = line_verticle(p0p1, p3)\n",
        "\n",
        "            new_p0 = line_cross_point(p0p1, p0p1_verticle)\n",
        "            return np.array([new_p0, p1, new_p2, p3], dtype=np.float32)\n",
        "        else:\n",
        "            p0p3 = fit_line([p0[0], p3[0]], [p0[1], p3[1]])\n",
        "            p0p3_verticle = line_verticle(p0p3, p1)\n",
        "\n",
        "            new_p0 = line_cross_point(p0p3, p0p3_verticle)\n",
        "            p1p2 = fit_line([p1[0], p2[0]], [p1[1], p2[1]])\n",
        "            p1p2_verticle = line_verticle(p1p2, p3)\n",
        "\n",
        "            new_p2 = line_cross_point(p1p2, p1p2_verticle)\n",
        "            return np.array([new_p0, p1, new_p2, p3], dtype=np.float32)\n",
        "\n",
        "#Sorting a rectangle to get all point in clockwies manner\n",
        "def sort_rectangle(poly):\n",
        "    '''sort the four coordinates of the polygon, points in poly should be sorted clockwise'''\n",
        "    # First find the lowest point\n",
        "    p_lowest = np.argmax(poly[:, 1])\n",
        "    if np.count_nonzero(poly[:, 1] == poly[p_lowest, 1]) == 2:\n",
        "        # if the bottom line is parallel to x-axis, then p0 must be the upper-left corner\n",
        "        p0_index = np.argmin(np.sum(poly, axis=1))\n",
        "        p1_index = (p0_index + 1) % 4\n",
        "        p2_index = (p0_index + 2) % 4\n",
        "        p3_index = (p0_index + 3) % 4\n",
        "        return poly[[p0_index, p1_index, p2_index, p3_index]], 0.\n",
        "    else:\n",
        "        # find the point that sits right to the lowest point\n",
        "        p_lowest_right = (p_lowest - 1) % 4\n",
        "        p_lowest_left = (p_lowest + 1) % 4\n",
        "        angle = np.arctan(-(poly[p_lowest][1] - poly[p_lowest_right][1])/(poly[p_lowest][0] - poly[p_lowest_right][0]))\n",
        "        # assert angle > 0\n",
        "        if angle <= 0:\n",
        "            print(angle, poly[p_lowest], poly[p_lowest_right])\n",
        "        if angle/np.pi * 180 > 45:\n",
        "            #this point is p2\n",
        "            p2_index = p_lowest\n",
        "            p1_index = (p2_index - 1) % 4\n",
        "            p0_index = (p2_index - 2) % 4\n",
        "            p3_index = (p2_index + 1) % 4\n",
        "            return poly[[p0_index, p1_index, p2_index, p3_index]], -(np.pi/2 - angle)\n",
        "        else:\n",
        "            # this point is p3\n",
        "            p3_index = p_lowest\n",
        "            p0_index = (p3_index + 1) % 4\n",
        "            p1_index = (p3_index + 2) % 4\n",
        "            p2_index = (p3_index + 3) % 4\n",
        "            return poly[[p0_index, p1_index, p2_index, p3_index]], angle\n",
        "\n",
        "\n",
        "def restore_rectangle_rbox(origin, geometry):\n",
        "    ''' Resotre rectangle tbox'''\n",
        "    d = geometry[:, :4]\n",
        "    angle = geometry[:, 4]\n",
        "    # for angle > 0\n",
        "    origin_0 = origin[angle >= 0]\n",
        "    d_0 = d[angle >= 0]\n",
        "    angle_0 = angle[angle >= 0]\n",
        "    if origin_0.shape[0] > 0:\n",
        "        p = np.array([np.zeros(d_0.shape[0]), -d_0[:, 0] - d_0[:, 2],\n",
        "                      d_0[:, 1] + d_0[:, 3], -d_0[:, 0] - d_0[:, 2],\n",
        "                      d_0[:, 1] + d_0[:, 3], np.zeros(d_0.shape[0]),\n",
        "                      np.zeros(d_0.shape[0]), np.zeros(d_0.shape[0]),\n",
        "                      d_0[:, 3], -d_0[:, 2]])\n",
        "        p = p.transpose((1, 0)).reshape((-1, 5, 2))  # N*5*2\n",
        "\n",
        "        rotate_matrix_x = np.array([np.cos(angle_0), np.sin(angle_0)]).transpose((1, 0))\n",
        "        rotate_matrix_x = np.repeat(rotate_matrix_x, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))  # N*5*2\n",
        "\n",
        "        rotate_matrix_y = np.array([-np.sin(angle_0), np.cos(angle_0)]).transpose((1, 0))\n",
        "        rotate_matrix_y = np.repeat(rotate_matrix_y, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))\n",
        "\n",
        "        p_rotate_x = np.sum(rotate_matrix_x * p, axis=2)[:, :, np.newaxis]  # N*5*1\n",
        "        p_rotate_y = np.sum(rotate_matrix_y * p, axis=2)[:, :, np.newaxis]  # N*5*1\n",
        "\n",
        "        p_rotate = np.concatenate([p_rotate_x, p_rotate_y], axis=2)  # N*5*2\n",
        "\n",
        "        p3_in_origin = origin_0 - p_rotate[:, 4, :]\n",
        "        new_p0 = p_rotate[:, 0, :] + p3_in_origin  # N*2\n",
        "        new_p1 = p_rotate[:, 1, :] + p3_in_origin\n",
        "        new_p2 = p_rotate[:, 2, :] + p3_in_origin\n",
        "        new_p3 = p_rotate[:, 3, :] + p3_in_origin\n",
        "\n",
        "        new_p_0 = np.concatenate([new_p0[:, np.newaxis, :], new_p1[:, np.newaxis, :],\n",
        "                                  new_p2[:, np.newaxis, :], new_p3[:, np.newaxis, :]], axis=1)  # N*4*2\n",
        "    else:\n",
        "        new_p_0 = np.zeros((0, 4, 2))\n",
        "    # for angle < 0\n",
        "    origin_1 = origin[angle < 0]\n",
        "    d_1 = d[angle < 0]\n",
        "    angle_1 = angle[angle < 0]\n",
        "    if origin_1.shape[0] > 0:\n",
        "        p = np.array([-d_1[:, 1] - d_1[:, 3], -d_1[:, 0] - d_1[:, 2],\n",
        "                      np.zeros(d_1.shape[0]), -d_1[:, 0] - d_1[:, 2],\n",
        "                      np.zeros(d_1.shape[0]), np.zeros(d_1.shape[0]),\n",
        "                      -d_1[:, 1] - d_1[:, 3], np.zeros(d_1.shape[0]),\n",
        "                      -d_1[:, 1], -d_1[:, 2]])\n",
        "        p = p.transpose((1, 0)).reshape((-1, 5, 2))  # N*5*2\n",
        "\n",
        "        rotate_matrix_x = np.array([np.cos(-angle_1), -np.sin(-angle_1)]).transpose((1, 0))\n",
        "        rotate_matrix_x = np.repeat(rotate_matrix_x, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))  # N*5*2\n",
        "\n",
        "        rotate_matrix_y = np.array([np.sin(-angle_1), np.cos(-angle_1)]).transpose((1, 0))\n",
        "        rotate_matrix_y = np.repeat(rotate_matrix_y, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))\n",
        "\n",
        "        p_rotate_x = np.sum(rotate_matrix_x * p, axis=2)[:, :, np.newaxis]  # N*5*1\n",
        "        p_rotate_y = np.sum(rotate_matrix_y * p, axis=2)[:, :, np.newaxis]  # N*5*1\n",
        "\n",
        "        p_rotate = np.concatenate([p_rotate_x, p_rotate_y], axis=2)  # N*5*2\n",
        "\n",
        "        p3_in_origin = origin_1 - p_rotate[:, 4, :]\n",
        "        new_p0 = p_rotate[:, 0, :] + p3_in_origin  # N*2\n",
        "        new_p1 = p_rotate[:, 1, :] + p3_in_origin\n",
        "        new_p2 = p_rotate[:, 2, :] + p3_in_origin\n",
        "        new_p3 = p_rotate[:, 3, :] + p3_in_origin\n",
        "\n",
        "        new_p_1 = np.concatenate([new_p0[:, np.newaxis, :], new_p1[:, np.newaxis, :],\n",
        "                                  new_p2[:, np.newaxis, :], new_p3[:, np.newaxis, :]], axis=1)  # N*4*2\n",
        "    else:\n",
        "        new_p_1 = np.zeros((0, 4, 2))\n",
        "    return np.concatenate([new_p_0, new_p_1])\n",
        "\n",
        "\n",
        "#Some geometrical functions used in codes\n",
        "def restore_rectangle(origin, geometry):\n",
        "    return restore_rectangle_rbox(origin, geometry)\n",
        "\n",
        "def getRotateRect(box):\n",
        "    rect = cv2.minAreaRect(box)\n",
        "\n",
        "    angle=rect[2]  # angle = [-90, 0)\n",
        "    if angle < -45:\n",
        "        rect = (rect[0], (rect[1][0], rect[1][1]), rect[2])\n",
        "        angle += 90\n",
        "        size = (rect[1][1],rect[1][0])\n",
        "    else:\n",
        "        rect = (rect[0], (rect[1][0], rect[1][1]), rect[2])\n",
        "        size=rect[1]\n",
        "\n",
        "    box_ = cv2.boxPoints(rect)\n",
        "    return np.concatenate([rect[0], size]), angle, box_\n",
        "\n",
        "\n",
        "#These Functions are used to Generate ROI params like out box,crop box & angles that we use to crop text from image\n",
        "def generate_roiRotatePara(box, angle, expand_w = 60):\n",
        "    '''Generate all ROI Parameterts'''\n",
        "    p0_rect, p1_rect, p2_rect, p3_rect = box\n",
        "    cxy = (p0_rect + p2_rect) / 2.\n",
        "    size = np.array([np.linalg.norm(p0_rect - p1_rect), np.linalg.norm(p0_rect - p3_rect)])\n",
        "    rrect = np.concatenate([cxy, size])\n",
        "\n",
        "    box=np.array(box)\n",
        "\n",
        "    points=np.array(box, dtype=np.int32)\n",
        "    xmin=np.min(points[:,0])\n",
        "    xmax=np.max(points[:,0])\n",
        "    ymin=np.min(points[:,1])\n",
        "    ymax=np.max(points[:,1])\n",
        "    bbox = np.array([xmin, ymin, xmax, ymax])\n",
        "    if np.any(bbox < -expand_w):\n",
        "        return None\n",
        "    \n",
        "    rrect[:2] -= bbox[:2]\n",
        "    rrect[:2] -= rrect[2:] / 2\n",
        "    rrect[2:] += rrect[:2]\n",
        "\n",
        "    bbox[2:] -= bbox[:2]\n",
        "\n",
        "    rrect[::2] = np.clip(rrect[::2], 0, bbox[2])\n",
        "    rrect[1::2] = np.clip(rrect[1::2], 0, bbox[3])\n",
        "    rrect[2:] -= rrect[:2]\n",
        "    \n",
        "    return bbox.astype(np.int32), rrect.astype(np.int32), - angle\n",
        "\n",
        "def restore_roiRotatePara(box):\n",
        "    rectange, rotate_angle = sort_rectangle(box)\n",
        "    return generate_roiRotatePara(rectange, rotate_angle)\n",
        "\n",
        "#This function is used to generate geo_map,score_map, training_mask,corp_box,out_box,angle that we use while training model\n",
        "def generate_rbox(im_size, polys, tags):\n",
        "    '''Genrate score_map and geo_map for image'''\n",
        "    h, w = im_size\n",
        "    poly_mask = np.zeros((h, w), dtype=np.uint8)\n",
        "    score_map = np.zeros((h, w), dtype=np.uint8)\n",
        "    geo_map = np.zeros((h, w, 5), dtype=np.float32)\n",
        "\n",
        "    outBoxs = []\n",
        "    cropBoxs = []\n",
        "    angles = []\n",
        "    text_tags = []\n",
        "    recg_masks = []\n",
        "    # mask used during traning, to ignore some hard areas\n",
        "    training_mask = np.ones((h, w), dtype=np.uint8)\n",
        "    for poly_idx, poly_tag in enumerate(zip(polys, tags)):\n",
        "        poly = poly_tag[0]\n",
        "        #print(poly)\n",
        "        tag = poly_tag[1]\n",
        "        #print(tag)\n",
        "        r = [None, None, None, None]\n",
        "        for i in range(4):\n",
        "            r[i] = min(np.linalg.norm(poly[i] - poly[(i + 1) % 4]),\n",
        "                       np.linalg.norm(poly[i] - poly[(i - 1) % 4]))\n",
        "        # score map\n",
        "        shrinked_poly = shrink_poly(poly.copy(), r).astype(np.int32)[np.newaxis, :, :]\n",
        "        cv2.fillPoly(score_map, shrinked_poly, 1)\n",
        "        cv2.fillPoly(poly_mask, shrinked_poly, poly_idx + 1)\n",
        "\n",
        "        # if geometry == 'RBOX':\n",
        "        # generate a parallelogram for any combination of two vertices\n",
        "        fitted_parallelograms = []\n",
        "        for i in range(4):\n",
        "            p0 = poly[i]\n",
        "            p1 = poly[(i + 1) % 4]\n",
        "            p2 = poly[(i + 2) % 4]\n",
        "            p3 = poly[(i + 3) % 4]\n",
        "            edge = fit_line([p0[0], p1[0]], [p0[1], p1[1]])\n",
        "            backward_edge = fit_line([p0[0], p3[0]], [p0[1], p3[1]])\n",
        "            forward_edge = fit_line([p1[0], p2[0]], [p1[1], p2[1]])\n",
        "            if point_dist_to_line(p0, p1, p2) > point_dist_to_line(p0, p1, p3):\n",
        "                #  parallel lines through p2\n",
        "                if edge[1] == 0:\n",
        "                    edge_opposite = [1, 0, -p2[0]]\n",
        "                else:\n",
        "                    edge_opposite = [edge[0], -1, p2[1] - edge[0] * p2[0]]\n",
        "            else:\n",
        "                # after p3\n",
        "                if edge[1] == 0:\n",
        "                    edge_opposite = [1, 0, -p3[0]]\n",
        "                else:\n",
        "                    edge_opposite = [edge[0], -1, p3[1] - edge[0] * p3[0]]\n",
        "            # move forward edge\n",
        "            new_p0 = p0\n",
        "            new_p1 = p1\n",
        "            new_p2 = p2\n",
        "            new_p3 = p3\n",
        "            new_p2 = line_cross_point(forward_edge, edge_opposite)\n",
        "            if point_dist_to_line(p1, new_p2, p0) > point_dist_to_line(p1, new_p2, p3):\n",
        "                # across p0\n",
        "                if forward_edge[1] == 0:\n",
        "                    forward_opposite = [1, 0, -p0[0]]\n",
        "                else:\n",
        "                    forward_opposite = [forward_edge[0], -1, p0[1] - forward_edge[0] * p0[0]]\n",
        "            else:\n",
        "                # across p3\n",
        "                if forward_edge[1] == 0:\n",
        "                    forward_opposite = [1, 0, -p3[0]]\n",
        "                else:\n",
        "                    forward_opposite = [forward_edge[0], -1, p3[1] - forward_edge[0] * p3[0]]\n",
        "            new_p0 = line_cross_point(forward_opposite, edge)\n",
        "            new_p3 = line_cross_point(forward_opposite, edge_opposite)\n",
        "            fitted_parallelograms.append([new_p0, new_p1, new_p2, new_p3, new_p0])\n",
        "            # or move backward edge\n",
        "            new_p0 = p0\n",
        "            new_p1 = p1\n",
        "            new_p2 = p2\n",
        "            new_p3 = p3\n",
        "            new_p3 = line_cross_point(backward_edge, edge_opposite)\n",
        "            if point_dist_to_line(p0, p3, p1) > point_dist_to_line(p0, p3, p2):\n",
        "                # across p1\n",
        "                if backward_edge[1] == 0:\n",
        "                    backward_opposite = [1, 0, -p1[0]]\n",
        "                else:\n",
        "                    backward_opposite = [backward_edge[0], -1, p1[1] - backward_edge[0] * p1[0]]\n",
        "            else:\n",
        "                # across p2\n",
        "                if backward_edge[1] == 0:\n",
        "                    backward_opposite = [1, 0, -p2[0]]\n",
        "                else:\n",
        "                    backward_opposite = [backward_edge[0], -1, p2[1] - backward_edge[0] * p2[0]]\n",
        "            new_p1 = line_cross_point(backward_opposite, edge)\n",
        "            new_p2 = line_cross_point(backward_opposite, edge_opposite)\n",
        "            fitted_parallelograms.append([new_p0, new_p1, new_p2, new_p3, new_p0])\n",
        "        areas = [Polygon(t).area for t in fitted_parallelograms]\n",
        "        parallelogram = np.array(fitted_parallelograms[np.argmin(areas)][:-1], dtype=np.float32)\n",
        "        # sort thie polygon\n",
        "        parallelogram_coord_sum = np.sum(parallelogram, axis=1)\n",
        "        min_coord_idx = np.argmin(parallelogram_coord_sum)\n",
        "        parallelogram = parallelogram[\n",
        "            [min_coord_idx, (min_coord_idx + 1) % 4, (min_coord_idx + 2) % 4, (min_coord_idx + 3) % 4]]\n",
        "\n",
        "        rectange = rectangle_from_parallelogram(parallelogram)\n",
        "        rectange, rotate_angle = sort_rectangle(rectange)\n",
        "\n",
        "        p0_rect, p1_rect, p2_rect, p3_rect = rectange\n",
        "\n",
        "        # if the poly is too small, then ignore it during training\n",
        "        poly_h = min(np.linalg.norm(p0_rect - p3_rect), np.linalg.norm(p1_rect - p2_rect))\n",
        "        poly_w = min(np.linalg.norm(p0_rect - p1_rect), np.linalg.norm(p2_rect - p3_rect))\n",
        "\n",
        "        invaild = (min(poly_h, poly_w) < 6) or tag is None or (True and poly_h > poly_w * 2)\n",
        "\n",
        "        if invaild:\n",
        "            cv2.fillPoly(training_mask, poly.astype(np.int32)[np.newaxis, :, :], 0)\n",
        "        xy_in_poly = np.argwhere(poly_mask == (poly_idx + 1))\n",
        "        \n",
        "        if not invaild:\n",
        "            roiRotatePara = generate_roiRotatePara(rectange, rotate_angle)\n",
        "            if roiRotatePara:\n",
        "                outBox, cropBox, angle = roiRotatePara\n",
        "                if min(cropBox[2:]) > 6:\n",
        "                    w , h = cropBox[2:]\n",
        "                    textImgW = np.ceil(min(w / float(h) * 32, 256) / 4 /1)\n",
        "                    #print(tag)\n",
        "                    if textImgW >= 2 * min(len(tag), 16):  # avoid CTC error\n",
        "                        outBoxs.append(outBox)\n",
        "                        cropBoxs.append(cropBox)\n",
        "                        angles.append(angle)\n",
        "                        text_tags.append(tag[:16])\n",
        "                        recg_masks.append(1.)\n",
        "\n",
        "        for y, x in xy_in_poly:\n",
        "            point = np.array([x, y], dtype=np.float32)\n",
        "            # top\n",
        "            geo_map[y, x, 0] = point_dist_to_line(p0_rect, p1_rect, point) + 3\n",
        "            # right\n",
        "            geo_map[y, x, 1] = point_dist_to_line(p1_rect, p2_rect, point) + 3\n",
        "            # down\n",
        "            geo_map[y, x, 2] = point_dist_to_line(p2_rect, p3_rect, point) + 3\n",
        "            # left\n",
        "            geo_map[y, x, 3] = point_dist_to_line(p3_rect, p0_rect, point) + 3\n",
        "            # angle\n",
        "            geo_map[y, x, 4] = rotate_angle\n",
        "    if len(outBoxs) == 0:\n",
        "        outBoxs.append([0, 0, 2 * 4, 2 * 4]) # keep extract From sharedConv feature map not zero\n",
        "        cropBoxs.append([0, 0, 2 * 4, 2 * 4])\n",
        "        angles.append(0.)\n",
        "        text_tags.append([NUM_CLASSES - 2])\n",
        "        recg_masks.append(0.)\n",
        "\n",
        "    outBoxs = np.array(outBoxs, np.int32)\n",
        "    cropBoxs = np.array(cropBoxs, np.int32)\n",
        "    angles = np.array(angles, np.float32)\n",
        "\n",
        "    return score_map, geo_map, training_mask, (outBoxs, cropBoxs, angles), text_tags, recg_masks\n",
        "    \n",
        "class Deconv(tf.keras.layers.Layer):\n",
        "  def __init__(self,name=\"deconv\"):\n",
        "    super().__init__(name)\n",
        "    self.inp_size=0\n",
        "    self.conv=None\n",
        "    self.upsample=None\n",
        "    self.bn=None\n",
        "  def build(self,imshape):\n",
        "    self.inp_size=imshape\n",
        "    self.bn=tf.keras.layers.BatchNormalization()\n",
        "    self.conv=tf.keras.layers.Conv2D(filters=self.inp_size[-1]//2,kernel_size=3,padding='same',activation='relu',kernel_initializer=tf.keras.initializers.GlorotNormal(seed=12),use_bias=False)\n",
        "    self.upsample=tf.keras.layers.UpSampling2D(size=(2,2),interpolation='bilinear',data_format='channels_last',)\n",
        "  def call(self,X):\n",
        "    \n",
        "    x1=self.upsample(X)\n",
        "    x1=self.conv(x1)\n",
        "    x1=self.bn(x1)\n",
        "    x1=tf.keras.activations.relu(x1)\n",
        "    return x1\n",
        "resnet=tf.keras.applications.ResNet50(input_shape=(512,512,3),include_top=False,weights='imagenet')\n",
        "tf.keras.backend.clear_session()\n",
        "layers=resnet.layers\n",
        "x1,x2,x3,x4=None,None,None,None\n",
        "for i in range(len(layers)): \n",
        "  x=layers[i]\n",
        "  if x.name=='pool1_pool':\n",
        "    x1=x\n",
        "  if x.name=='conv3_block1_1_conv':\n",
        "    x2=x\n",
        "  if x.name=='conv4_block1_1_conv':\n",
        "    x3=x   \n",
        "  if x.name=='conv5_block3_2_conv':\n",
        "    x4=x  \n",
        "  #  input_1 ,conv1_relu\n",
        "d=x4.output\n",
        "d=Deconv('deconv1')(d)\n",
        "d=tf.keras.layers.add([d,x3.output])\n",
        "\n",
        "d=Deconv('deconv2')(d)\n",
        "d=tf.keras.layers.add([d,x2.output])\n",
        "\n",
        "d=Deconv('deconv3')(d)\n",
        "d=tf.keras.layers.add([d,x1.output])\n",
        "d=tf.keras.layers.BatchNormalization()(d)\n",
        "d=Deconv('deconv4')(d)\n",
        "d=Deconv('deconv5')(d)\n",
        "score=tf.keras.layers.Conv2D(1,kernel_size=3,padding='same',activation='sigmoid')(d)\n",
        "\n",
        "# Used this beacause sigmoid gives values in range of 0-1(as mentioned in git repository)\n",
        "geo_map=tf.keras.layers.Conv2D(4,kernel_size=3,padding='same',activation='sigmoid')(d)*512\n",
        "#Angles are assumed to be between [-45 to 45]\n",
        "angle_map=(tf.keras.layers.Conv2D(1,kernel_size=3,padding='same',activation='sigmoid')(d)-0.5)*np.pi/2\n",
        "out=tf.concat([score,geo_map,angle_map],axis=3)\n",
        "detector=tf.keras.Model(resnet.input,out,name='detector')\n",
        "\n",
        "for layers in resnet.layers:\n",
        "  layers.trainable=False\n",
        "#detector.load_weights('C:/Users/sayon/Documents/detector.h5')\n",
        "detector.load_weights('/content/detector.h5')\n",
        "#These Are Function that will be used while converting geo_maps to score_maps and returns bounding boxes for image after nms\n",
        "\n",
        "def sort_poly(p):\n",
        "  min_axis = np.argmin(np.sum(p, axis=1))\n",
        "  p = p[[min_axis, (min_axis+1)%4, (min_axis+2)%4, (min_axis+3)%4]]\n",
        "  if abs(p[0, 0] - p[1, 0]) > abs(p[0, 1] - p[1, 1]):\n",
        "    return p\n",
        "  else:\n",
        "    return p[[0, 3, 2, 1]]\n",
        "def intersection(g, p):\n",
        "    g = Polygon(g[:8].reshape((4, 2)))\n",
        "    p = Polygon(p[:8].reshape((4, 2)))\n",
        "    if not g.is_valid or not p.is_valid:\n",
        "        return 0\n",
        "    inter = Polygon(g).intersection(Polygon(p)).area\n",
        "    union = g.area + p.area - inter\n",
        "    if union == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return inter/union\n",
        "\n",
        "\n",
        "def weighted_merge(g, p):\n",
        "    g[:8] = (g[8] * g[:8] + p[8] * p[:8])/(g[8] + p[8])\n",
        "    g[8] = (g[8] + p[8])\n",
        "    return g\n",
        "\n",
        "\n",
        "def standard_nms(S, thres):\n",
        "    order = np.argsort(S[:, 8])[::-1]\n",
        "    keep = []\n",
        "    while order.size > 0:\n",
        "        i = order[0]\n",
        "        keep.append(i)\n",
        "        ovr = np.array([intersection(S[i], S[t]) for t in order[1:]])\n",
        "\n",
        "        inds = np.where(ovr <= thres)[0]\n",
        "        order = order[inds+1]\n",
        "\n",
        "    return S[keep]\n",
        "\n",
        "\n",
        "def nms_locality(polys, thres=0.3):\n",
        "    '''\n",
        "    :param polys: a N*9 numpy array. first 8 coordinates, then prob\n",
        "    :return: boxes after nms\n",
        "    '''\n",
        "    S = []\n",
        "    p = None\n",
        "  \n",
        "    for g in polys:\n",
        "        if p is not None and intersection(g, p) > thres:\n",
        "        \n",
        "            p = weighted_merge(g, p)\n",
        "        else:\n",
        "            if p is not None:\n",
        "                S.append(p)\n",
        "            p = g\n",
        "  \n",
        "    if p is not None:\n",
        "        S.append(p)\n",
        "\n",
        "    if len(S) == 0:\n",
        "        return np.array([])\n",
        "    \n",
        "    return standard_nms(np.array(S), thres)\n",
        "\n",
        "inputs = tf.keras.layers.Input(name='the_input', shape=(64,128,3), dtype='float32')  \n",
        "\n",
        "inner = tf.keras.layers.Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(inputs) \n",
        "inner = tf.keras.layers.BatchNormalization()(inner)\n",
        "inner = tf.keras.layers.Activation('relu')(inner)\n",
        "inner = tf.keras.layers.MaxPooling2D(pool_size=(2, 1), name='max1')(inner)  \n",
        "\n",
        "inner = tf.keras.layers.Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)  \n",
        "inner = tf.keras.layers.BatchNormalization()(inner)\n",
        "inner = tf.keras.layers.Activation('relu')(inner)\n",
        "inner = tf.keras.layers.MaxPooling2D(pool_size=(2, 1), name='max2')(inner)  \n",
        "\n",
        "inner = tf.keras.layers.Conv2D(32, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)  \n",
        "inner = tf.keras.layers.BatchNormalization()(inner)\n",
        "inner = tf.keras.layers.Activation('relu')(inner)\n",
        "inner = tf.keras.layers.Conv2D(32, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(inner)  \n",
        "inner = tf.keras.layers.BatchNormalization()(inner)\n",
        "inner = tf.keras.layers.Activation('relu')(inner)\n",
        "inner = tf.keras.layers.MaxPooling2D(pool_size=(2, 1), name='max3')(inner)  \n",
        "\n",
        "inner = tf.keras.layers.Conv2D(32, (3, 3), padding='same', name='conv5', kernel_initializer='he_normal')(inner)  \n",
        "inner = tf.keras.layers.BatchNormalization()(inner)\n",
        "inner = tf.keras.layers.Activation('relu')(inner)\n",
        "inner = tf.keras.layers.Conv2D(32, (3, 3), padding='same', name='conv6')(inner)   \n",
        "inner = tf.keras.layers.BatchNormalization()(inner)\n",
        "inner = tf.keras.layers.Activation('relu')(inner)\n",
        "inner = tf.keras.layers.MaxPooling2D(pool_size=(2, 1), name='max4')(inner)  \n",
        "\n",
        "inner = tf.keras.layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', name='con7')(inner) \n",
        "inner = tf.keras.layers.BatchNormalization()(inner)\n",
        "inner = tf.keras.layers.Activation('relu')(inner)\n",
        "inner = tf.keras.layers.Reshape(target_shape=((64,512)), name='reshape')(inner)  \n",
        "inner = tf.keras.layers.Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner) \n",
        "\n",
        "out=tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32,return_sequences=True,go_backwards=True))(inner)\n",
        "out=tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128,return_sequences=True,go_backwards=True))(out)\n",
        "x=tf.keras.layers.Dense(100)(out)#Here we hve given 100 bcz vocab size is 99 and 1 extra is for blank symbol\n",
        "x=tf.keras.activations.softmax(x)\n",
        "recognizer=tf.keras.models.Model(inputs,x)\n",
        "#recognizer.load_weights('C:/Users/sayon/Downloads/recognizer_best_1.h5')\n",
        "recognizer.load_weights('/content/recognizer_best_1 (1).h5')\n",
        "\n",
        "\n",
        "def inferencePipeline(img):\n",
        "  '''This function is main complete pipeline of our Model'''\n",
        "  start_time=time.time()\n",
        "  \n",
        "  #1.Text Detection\n",
        "  img=cv2.resize(img,(512,512))\n",
        "  ii=detector.predict(np.expand_dims(img,axis=0))\n",
        "  score_map=ii[0][:,:,0]\n",
        "  geo_map=ii[0][:,:,1:]\n",
        "\n",
        "\n",
        "  for ind in [0,1,2,3,4]:\n",
        "    geo_map[:,:,ind]*=score_map\n",
        "\n",
        "\n",
        "  #2.ROI Rotate  \n",
        "  score_map_thresh=0.5\n",
        "  box_thresh=0.1 \n",
        "  nms_thres=0.2\n",
        "  if len(score_map.shape) == 4:\n",
        "    score_map = score_map[0, :, :, 0]\n",
        "    geo_map = geo_map[0, :, :, :]\n",
        "  # filter the score map\n",
        "  xy_text = np.argwhere(score_map > score_map_thresh)\n",
        "  # sort the text boxes via the y axis\n",
        "  xy_text = xy_text[np.argsort(xy_text[:, 0])]\n",
        "  # restore\n",
        "  text_box_restored = restore_rectangle(xy_text[:, ::-1], geo_map[xy_text[:, 0], xy_text[:, 1], :]) # N*4*2\n",
        "  boxes = np.zeros((text_box_restored.shape[0], 9), dtype=np.float32)\n",
        "  boxes[:, :8] = text_box_restored.reshape((-1, 8))\n",
        "  boxes[:, 8] = score_map[xy_text[:, 0], xy_text[:, 1]]\n",
        "  boxes = nms_locality(boxes.astype(np.float64), nms_thres)\n",
        "  # boxes = np.concatenate([boxes, _boxes], axis=0)\n",
        "\n",
        "  # here we filter some low score boxes by the average score map, this is different from the orginal paper\n",
        "  for i, box in enumerate(boxes):\n",
        "    mask = np.zeros_like(score_map, dtype=np.uint8)\n",
        "    cv2.fillPoly(mask, box[:8].reshape((-1, 4, 2)).astype(np.int32), 1)\n",
        "    boxes[i, 8] = cv2.mean(score_map, mask)[0]\n",
        "    if i==4:\n",
        "      break\n",
        "  if len(boxes)>0:\n",
        "    boxes = boxes[boxes[:, 8] > box_thresh]\n",
        "  boxes[:,:8:2] = np.clip(boxes[:,:8:2], 0, 512 - 1)\n",
        "  boxes[:,1:8:2] = np.clip(boxes[:,1:8:2], 0, 512 - 1)  \n",
        "  res = []\n",
        "  result = []\n",
        "  if len(boxes)>0:\n",
        "    for box in boxes:\n",
        "      box_ =  box[:8].reshape((4, 2))\n",
        "      if np.linalg.norm(box_[0] - box_[1]) < 8 or np.linalg.norm(box_[3]-box_[0]) < 8:\n",
        "        continue\n",
        "      result.append(box_)\n",
        "  res.append(np.array(result, np.float32))   \n",
        "\n",
        "  box_index = []\n",
        "  brotateParas = []\n",
        "  filter_bsharedFeatures = []\n",
        "  for i in range(len(res)):\n",
        "    rotateParas = []\n",
        "    rboxes=res[i]\n",
        "    txt=[]\n",
        "    for j, rbox in enumerate(rboxes):\n",
        "      para = restore_roiRotatePara(rbox)\n",
        "      if para and min(para[1][2:]) > 8:\n",
        "        rotateParas.append(para)\n",
        "        box_index.append((i, j))\n",
        "    pts=[]   \n",
        "    \n",
        "    \n",
        "    #3. Text Recognition (From boxes given by Text Detection+ROI Rotate) \n",
        "    \n",
        "    if len(rotateParas) > 0:\n",
        "      for num in range(len(rotateParas)):\n",
        "        text=\"\"\n",
        "        out=rotateParas[num][0]\n",
        "        crop=rotateParas[num][1]\n",
        "        points=np.array([[out[0],out[1]],[out[0]+out[2],out[1]],[out[0]+out[2],out[1]+out[3]],[out[0],out[1]+out[3]]])\n",
        "        angle=rotateParas[num][2] \n",
        "        img1=tf.image.crop_to_bounding_box(img,out[1],out[0],out[3],out[2])\n",
        "        img2=tf.keras.preprocessing.image.random_rotation(img1,angle)\n",
        "        img2=tf.image.crop_to_bounding_box(img2,crop[1],crop[0],crop[3],crop[2]).numpy()\n",
        "        img2=cv2.resize(img2,(128,64))\n",
        "        img2=cv2.detailEnhance(img2)\n",
        "        ii=recognizer.predict(np.expand_dims(img2,axis=0))\n",
        "        arr=tf.keras.backend.ctc_decode(ii,np.ones((1),'int8')*64,)\n",
        "        for val in arr[0][0].numpy()[0]:\n",
        "          if val==-1:\n",
        "            break\n",
        "          else:\n",
        "            text+=index_char[val]\n",
        "        txt.append(text)\n",
        "        pts.append(points)\n",
        "    \n",
        "    # 4. Labeling detected and Recognized Text in Image\n",
        "    \n",
        "    for i in range(len(txt)):\n",
        "      cv2.polylines(img,[pts[i]],isClosed=True,color=(255,255,0),thickness=2)\n",
        "      cv2.putText(img,txt[i],(pts[i][0][0],pts[i][0][1]),cv2.FONT_HERSHEY_SIMPLEX,0.8, (0, 0, 255), 3)\n",
        "    end_time=time.time()\n",
        "    print(\"Time Taken By Pipeline=\"+str(end_time-start_time)+\" seconds\")  \n",
        "    return img\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "st.title('Text recognition from Image')\n",
        "st.header('Upload your image')\n",
        "img=st.file_uploader('upload a image')\n",
        "if img:    \n",
        "  st.image(img,width=512)\n",
        "  image = Image.open(img)\n",
        "  img = np.array(image)\n",
        "  im=inferencePipeline(img)\n",
        "  #txt=','.join(txt)\n",
        "  im=cv2.resize(im,(512,400))\n",
        "  st.header('Resulted image')\n",
        "  st.image(im)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMUlWm9Kg-nE"
      },
      "source": [
        "!streamlit run app.py &>/dev/null&"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlj4cEh7g_vY",
        "outputId": "0556ea6a-85f9-4a3a-a527-3ec342ff4073"
      },
      "source": [
        "from pyngrok import ngrok\n",
        " \n",
        "public_url = ngrok.connect('8501')\n",
        "public_url"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"http://5b7042d4a28f.ngrok.io\" -> \"http://localhost:8501\">"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlKVD35HhCyU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}